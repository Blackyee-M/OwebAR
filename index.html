<!doctype html>
<html>
<head>
  <meta charset="utf-8">
  <title>WebAR MVP â€” Template Match</title>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <style>
    html,body {
      margin: 0;
      padding: 0;
      height: 100%;
      overflow: hidden;
      background: #000;
    }

    #startBtn {
      position: absolute;
      inset: 0;
      display: flex;
      justify-content: center;
      align-items: center;
      font-size: 30px;
      color: #fff;
      background: #000;
      z-index: 10;
      cursor: pointer;
    }

    #scanOverlay {
      position: absolute;
      inset: 0;
      display: none;
      justify-content: center;
      align-items: center;
      font-size: 22px;
      color: white;
      z-index: 8;
      pointer-events: none;
    }

    #canvasOutput {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      z-index: 1;
      object-fit: cover;
    }

    #threeContainer {
      position: absolute;
      inset: 0;
      z-index: 5;
      pointer-events: none;
    }
  </style>
</head>
<body>

<div id="startBtn">Tap to Start AR</div>
<div id="scanOverlay">Point your camera at the card</div>

<!-- Hidden overlay video -->
<video id="overlayVideo" src="./assets/video.mp4" loop muted playsinline style="display:none"></video>

<!-- OpenCV -->
<script async src="https://docs.opencv.org/4.x/opencv.js"></script>

<!-- Three.js -->
<script src="https://cdn.jsdelivr.net/npm/three@0.152.2/build/three.min.js"></script>

<div id="threeContainer"></div>
<canvas id="canvasOutput"></canvas>

<script>
let videoEl;
let grayMat, tmplMat, tmplGray;
let isRunning = false;
let renderer, scene, camera3, planeMesh;
let canvasOut, ctxOut;

const startBtn = document.getElementById("startBtn");
const scanOverlay = document.getElementById("scanOverlay");

// Wait for OpenCV to be ready
function cvReadyCheck() {
  if (typeof cv === "undefined" || !cv.Mat) {
    console.log("Waiting for OpenCV...");
    requestAnimationFrame(cvReadyCheck);
  } else {
    console.log("OpenCV ready!");
  }
}
cvReadyCheck();

async function startCamera() {
  videoEl = document.createElement("video");
  videoEl.setAttribute("playsinline", "");
  videoEl.autoplay = true;
  videoEl.muted = true;
  videoEl.style.display = "none";
  document.body.appendChild(videoEl);

  const stream = await navigator.mediaDevices.getUserMedia({
    video: { facingMode: "environment" }
  });

  videoEl.srcObject = stream;

  return new Promise((resolve) => {
    videoEl.onloadedmetadata = () => {
      videoEl.play();
      resolve();
    };
  });
}

function initThree() {
  const container = document.getElementById("threeContainer");
  renderer = new THREE.WebGLRenderer({ alpha: true });
  renderer.setSize(window.innerWidth, window.innerHeight);
  container.appendChild(renderer.domElement);

  scene = new THREE.Scene();
  camera3 = new THREE.PerspectiveCamera(
    60,
    window.innerWidth / window.innerHeight,
    0.01,
    100
  );
  camera3.position.set(0, 0, 2);

  const geom = new THREE.PlaneGeometry(1, 1);
  const tex = new THREE.VideoTexture(document.getElementById("overlayVideo"));
  const mat = new THREE.MeshBasicMaterial({ map: tex, transparent: true });
  planeMesh = new THREE.Mesh(geom, mat);
  planeMesh.visible = false;
  scene.add(planeMesh);

  function renderLoop() {
    renderer.render(scene, camera3);
    requestAnimationFrame(renderLoop);
  }
  renderLoop();
}

async function startAR() {
  await startCamera();

  canvasOut = document.getElementById("canvasOutput");
  canvasOut.width = window.innerWidth;
  canvasOut.height = window.innerHeight;
  ctxOut = canvasOut.getContext("2d");

  // Prepare OpenCV mats AFTER video starts
  const w = videoEl.videoWidth;
  const h = videoEl.videoHeight;

  grayMat = new cv.Mat(h, w, cv.CV_8UC1);

  // Load template image
  const img = new Image();
  img.src = "./assets/target.jpg";
  await new Promise((res) => (img.onload = res));

  const tmp = document.createElement("canvas");
  tmp.width = img.width;
  tmp.height = img.height;
  tmp.getContext("2d").drawImage(img, 0, 0);

  const data = tmp.getContext("2d").getImageData(0, 0, img.width, img.height);
  tmplMat = cv.matFromImageData(data);
  tmplGray = new cv.Mat();
  cv.cvtColor(tmplMat, tmplGray, cv.COLOR_RGBA2GRAY);

  initThree();

  isRunning = true;
  runLoop();
}

async function runLoop() {
  if (!isRunning) return;

  // Capture frame
  const w = videoEl.videoWidth;
  const h = videoEl.videoHeight;

  const tmp = document.createElement("canvas");
  tmp.width = w;
  tmp.height = h;
  tmp.getContext("2d").drawImage(videoEl, 0, 0, w, h);

  const id = tmp.getContext("2d").getImageData(0, 0, w, h);
  let frameRGBA = cv.matFromImageData(id);
  cv.cvtColor(frameRGBA, grayMat, cv.COLOR_RGBA2GRAY);
  frameRGBA.delete();

  ctxOut.drawImage(videoEl, 0, 0, canvasOut.width, canvasOut.height);

  // Simple match
  const result = new cv.Mat();
  cv.matchTemplate(grayMat, tmplGray, result, cv.TM_CCOEFF_NORMED);
  const mm = cv.minMaxLoc(result);
  result.delete();

  if (mm.maxVal > 0.55) {
    document.getElementById("overlayVideo").play();
    scanOverlay.style.display = "none";
    planeMesh.visible = true;
  } else {
    planeMesh.visible = false;
    scanOverlay.style.display = "flex";
  }

  requestAnimationFrame(runLoop);
}

startBtn.onclick = () => {
  startBtn.style.display = "none";
  scanOverlay.style.display = "flex";
  startAR();
};
</script>
</body>
</html>
